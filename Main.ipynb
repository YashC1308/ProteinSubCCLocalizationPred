{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Important things to know","metadata":{}},{"cell_type":"markdown","source":"* # You will need to run this file on Kaggle and use GPU-T4 X2 for Acceleration\n* # You will need a Huggingface Account : Signup here : https://huggingface.co\n* # You will need a WandDB account as well : Signup here : https://wandb.ai/","metadata":{}},{"cell_type":"code","source":"!pip install transformers\n!pip install evaluate\n!pip install datasets\n!pip install requests\n!pip install pandas","metadata":{"id":"4c5bf8d4","execution":{"iopub.status.busy":"2023-11-28T04:47:21.540509Z","iopub.execute_input":"2023-11-28T04:47:21.541340Z","iopub.status.idle":"2023-11-28T04:48:26.044112Z","shell.execute_reply.started":"2023-11-28T04:47:21.541305Z","shell.execute_reply":"2023-11-28T04:48:26.043129Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nCollecting evaluate\n  Obtaining dependency information for evaluate from https://files.pythonhosted.org/packages/70/63/7644a1eb7b0297e585a6adec98ed9e575309bb973c33b394dae66bc35c69/evaluate-0.4.1-py3-none-any.whl.metadata\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.24.3)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.17.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.1\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.10.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.5)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.17.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2023.7.22)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.0.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\nRequirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.24.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\n# Set the device to the first GPU\ndevice = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-28T04:48:26.046185Z","iopub.execute_input":"2023-11-28T04:48:26.046548Z","iopub.status.idle":"2023-11-28T04:48:26.052358Z","shell.execute_reply.started":"2023-11-28T04:48:26.046514Z","shell.execute_reply":"2023-11-28T04:48:26.051530Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Add your token from HuggingFace you can find it under Profile >> Access Tokens","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"id":"25b8526a","execution":{"iopub.status.busy":"2023-11-28T04:48:28.260042Z","iopub.execute_input":"2023-11-28T04:48:28.260773Z","iopub.status.idle":"2023-11-28T04:48:28.284584Z","shell.execute_reply.started":"2023-11-28T04:48:28.260741Z","shell.execute_reply":"2023-11-28T04:48:28.283647Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"413f18d56b7342f9929eb1910817f15d"}},"metadata":{}}]},{"cell_type":"markdown","source":"Then you need to install Git-LFS.","metadata":{"id":"ab8b2712"}},{"cell_type":"code","source":"!apt install git-lfs","metadata":{"id":"19e8f77c","execution":{"iopub.status.busy":"2023-11-28T04:48:37.423553Z","iopub.execute_input":"2023-11-28T04:48:37.424409Z","iopub.status.idle":"2023-11-28T04:48:40.699887Z","shell.execute_reply.started":"2023-11-28T04:48:37.424374Z","shell.execute_reply":"2023-11-28T04:48:40.698737Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\ngit-lfs is already the newest version (3.0.2-1ubuntu0.2).\n0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers.utils import send_example_telemetry\n\nsend_example_telemetry(\"protein_language_modeling_notebook\", framework=\"pytorch\")","metadata":{"id":"d107b8d9","execution":{"iopub.status.busy":"2023-11-28T04:48:44.283612Z","iopub.execute_input":"2023-11-28T04:48:44.284002Z","iopub.status.idle":"2023-11-28T04:48:44.388361Z","shell.execute_reply.started":"2023-11-28T04:48:44.283971Z","shell.execute_reply":"2023-11-28T04:48:44.387330Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Fine-Tuning Protein Language Models","metadata":{"id":"5c0749e1"}},{"cell_type":"markdown","source":"In this notebook, we're going to do some transfer learning to fine-tune some large, pre-trained protein language models on tasks of interest. \n\nThe specific model we're going to use is ESM-2, which is the state-of-the-art protein language model. The citation for this model is [Lin et al, 2022](https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1).\n\nThere are several ESM-2 checkpoints with differing model sizes. Larger models will generally have better accuracy, but they require more GPU memory and will take much longer to train. The available ESM-2 checkpoints (at time of writing) are:\n\n| Checkpoint name | Num layers | Num parameters |\n|------------------------------|----|----------|\n| `esm2_t48_15B_UR50D`         | 48 | 15B     |\n| `esm2_t36_3B_UR50D`          | 36 | 3B      |\n| `esm2_t33_650M_UR50D`        | 33 | 650M    |\n| `esm2_t30_150M_UR50D`        | 30 | 150M    |\n| `esm2_t12_35M_UR50D`         | 12 | 35M     |\n| `esm2_t6_8M_UR50D`           | 6  | 8M      |\n\nNote that the larger checkpoints may be very difficult to train without a large cloud GPU like an A100 or H100, and the largest 15B parameter checkpoint will probably be impossible to train on **any** single GPU! Also, note that memory usage for attention during training will scale as `O(batch_size * num_layers * seq_len^2)`, so larger models on long sequences will use quite a lot of memory! We will use the `esm2_t12_35M_UR50D` checkpoint for this notebook, which should train on any Colab instance or modern GPU.","metadata":{"id":"1d81db83"}},{"cell_type":"code","source":"model_checkpoint = \"facebook/esm2_t12_35M_UR50D\"","metadata":{"id":"32e605a2","execution":{"iopub.status.busy":"2023-11-28T04:48:49.640886Z","iopub.execute_input":"2023-11-28T04:48:49.641280Z","iopub.status.idle":"2023-11-28T04:48:49.645599Z","shell.execute_reply.started":"2023-11-28T04:48:49.641241Z","shell.execute_reply":"2023-11-28T04:48:49.644685Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Sequence classification / Protein SubCellular Localisation","metadata":{"id":"a8e6ac19"}},{"cell_type":"markdown","source":"One of the most common tasks you can perform with a language model is **sequence classification**. In sequence classification, we classify an entire protein into a category, from a list of two or more possibilities. There's no limit on the number of categories you can use, or the specific problem you choose, as long as it's something the model could in theory infer from the raw protein sequence.\nFor our Project we will be classifying proteins by their cellular localization - given their sequence, can we predict if they're going to be found in the Chloroplast or not?","metadata":{"id":"c3eb400c"}},{"cell_type":"markdown","source":"## Data preparation","metadata":{"id":"c5bc122f"}},{"cell_type":"markdown","source":"In this section, we're going to gather some training data from UniProt. Our goal is to create a pair of lists: `sequences` and `labels`. `sequences` will be a list of protein sequences, which will just be strings like \"MNKL...\", where each letter represents a single amino acid in the complete protein. `labels` will be a list of the category for each sequence. The categories will just be integers, with 1 representing the first category ie Protein is in **Chloroplast**, 0 representing the second ie **Not present in Chloroplast**. \n\nIn other words, if `sequences[i]` is a protein sequence then `labels[i]` should be its corresponding category. These will form the **training data** we're going to use to teach the model the task we want it to do.\n","metadata":{"id":"4c91d394"}},{"cell_type":"code","source":"import requests\n\nquery_url =\"https://rest.uniprot.org/uniprotkb/stream?compressed=true&fields=accession%2Creviewed%2Cid%2Ccc_subcellular_location%2Csequence&format=tsv&query=%28A.thaliana%29+AND+%28model_organism%3A3702%29+AND+%28reviewed%3Atrue%29\"","metadata":{"id":"c718ffbc","execution":{"iopub.status.busy":"2023-11-28T04:48:52.405192Z","iopub.execute_input":"2023-11-28T04:48:52.406180Z","iopub.status.idle":"2023-11-28T04:48:52.410285Z","shell.execute_reply.started":"2023-11-28T04:48:52.406142Z","shell.execute_reply":"2023-11-28T04:48:52.409354Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"This query URL might seem mysterious, but it isn't! To get it, we searched for `(A.thaliana) AND (reviewed:true) AND (length:[0 TO 512])` on UniProt to get a list of reasonably-sized Plant proteins,\nthen selected 'Download', and set the format to TSV and the columns to `Sequence` and `Subcellular location [CC]`, since those contain the data we care about for this task.\n\nOnce that's done, selecting `Generate URL for API` gives you a URL you can pass to Requests.","metadata":{"id":"3d2edc14"}},{"cell_type":"code","source":"uniprot_request = requests.get(query_url)","metadata":{"id":"dd03ef98","execution":{"iopub.status.busy":"2023-11-28T04:48:55.176522Z","iopub.execute_input":"2023-11-28T04:48:55.176908Z","iopub.status.idle":"2023-11-28T04:50:59.056852Z","shell.execute_reply.started":"2023-11-28T04:48:55.176877Z","shell.execute_reply":"2023-11-28T04:50:59.055938Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"To get this data into Pandas, we use a `BytesIO` object, which Pandas will treat like a file.","metadata":{"id":"b7217b77"}},{"cell_type":"code","source":"from io import BytesIO\nimport pandas\n\nbio = BytesIO(uniprot_request.content)\n\ndf = pandas.read_csv(bio, compression='gzip', sep='\\t')\ndf","metadata":{"id":"f2c05017","outputId":"7020375d-fb60-45b3-b055-f4f1ade70630","execution":{"iopub.status.busy":"2023-11-28T04:50:59.058873Z","iopub.execute_input":"2023-11-28T04:50:59.059184Z","iopub.status.idle":"2023-11-28T04:50:59.292485Z","shell.execute_reply.started":"2023-11-28T04:50:59.059157Z","shell.execute_reply":"2023-11-28T04:50:59.291609Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"            Entry  Reviewed   Entry Name  \\\n0      A0A0A7EPL0  reviewed  PIAL1_ARATH   \n1      A0A178VEK7  reviewed   DUO1_ARATH   \n2      A0A178WF56  reviewed  CSTM3_ARATH   \n3      A0A1I9LMX5  reviewed  PCEP9_ARATH   \n4      A0A1I9LN01  reviewed   LAF3_ARATH   \n...           ...       ...          ...   \n16296      Q9ZVR0  reviewed  PP2B6_ARATH   \n16297      Q9ZVR1  reviewed  PP2B5_ARATH   \n16298      Q9ZVR3  reviewed  PP2B4_ARATH   \n16299      Q9ZW38  reviewed  FBK36_ARATH   \n16300      Q9ZWC6  reviewed    ATB_ARATH   \n\n                               Subcellular location [CC]  \\\n0           SUBCELLULAR LOCATION: Nucleus {ECO:0000305}.   \n1      SUBCELLULAR LOCATION: Nucleus {ECO:0000255|PRO...   \n2      SUBCELLULAR LOCATION: Cell membrane {ECO:00002...   \n3      SUBCELLULAR LOCATION: [C-terminally encoded pe...   \n4      SUBCELLULAR LOCATION: Membrane {ECO:0000255}; ...   \n...                                                  ...   \n16296                                                NaN   \n16297                                                NaN   \n16298                                                NaN   \n16299                                                NaN   \n16300                                                NaN   \n\n                                                Sequence  \n0      MVIPATSRFGFRAEFNTKEFQASCISLANEIDAAIGRNEVPGNIQE...  \n1      MRKMEAKKEEIKKGPWKAEEDEVLINHVKRYGPRDWSSIRSKGLLQ...  \n2      MAQYHQQHEMKQTMAETQYVTAPPPMGYPVMMKDSPQTVQPPHEGQ...  \n3      MKLLSITLTSIVISMVFYQTPITTEARSLRKTNDQDHFKAGFTDDF...  \n4      MTGWYEFPVMIGFVSAAVFLLISVAYLPLLNDLYWSTLKSLTPPAG...  \n...                                                  ...  \n16296  MGQKLGVDSRQKIRQVLGSSSKVQKHDVESIGGGGGEIVPGHSPFD...  \n16297  MGQKHGVDTRGKGAEFCGCWEILTEFINGSSASFDDLPDDCLAIIS...  \n16298  MNTQILSQKTRYSAYIVYKTIYRFHGFKHIGVGFIGHGTPKAKRWE...  \n16299  MASISETSDDGSNGGDPNQKPEEPHKNPQEGKEEENQNEKPKEDDH...  \n16300  MEEVTRSVLAEEILKRLDLENLCSVACVSTTLRSAVVSGVLPSLTS...  \n\n[16301 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Entry</th>\n      <th>Reviewed</th>\n      <th>Entry Name</th>\n      <th>Subcellular location [CC]</th>\n      <th>Sequence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A0A0A7EPL0</td>\n      <td>reviewed</td>\n      <td>PIAL1_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000305}.</td>\n      <td>MVIPATSRFGFRAEFNTKEFQASCISLANEIDAAIGRNEVPGNIQE...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A0A178VEK7</td>\n      <td>reviewed</td>\n      <td>DUO1_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000255|PRO...</td>\n      <td>MRKMEAKKEEIKKGPWKAEEDEVLINHVKRYGPRDWSSIRSKGLLQ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A0A178WF56</td>\n      <td>reviewed</td>\n      <td>CSTM3_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Cell membrane {ECO:00002...</td>\n      <td>MAQYHQQHEMKQTMAETQYVTAPPPMGYPVMMKDSPQTVQPPHEGQ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0A1I9LMX5</td>\n      <td>reviewed</td>\n      <td>PCEP9_ARATH</td>\n      <td>SUBCELLULAR LOCATION: [C-terminally encoded pe...</td>\n      <td>MKLLSITLTSIVISMVFYQTPITTEARSLRKTNDQDHFKAGFTDDF...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A0A1I9LN01</td>\n      <td>reviewed</td>\n      <td>LAF3_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000255}; ...</td>\n      <td>MTGWYEFPVMIGFVSAAVFLLISVAYLPLLNDLYWSTLKSLTPPAG...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16296</th>\n      <td>Q9ZVR0</td>\n      <td>reviewed</td>\n      <td>PP2B6_ARATH</td>\n      <td>NaN</td>\n      <td>MGQKLGVDSRQKIRQVLGSSSKVQKHDVESIGGGGGEIVPGHSPFD...</td>\n    </tr>\n    <tr>\n      <th>16297</th>\n      <td>Q9ZVR1</td>\n      <td>reviewed</td>\n      <td>PP2B5_ARATH</td>\n      <td>NaN</td>\n      <td>MGQKHGVDTRGKGAEFCGCWEILTEFINGSSASFDDLPDDCLAIIS...</td>\n    </tr>\n    <tr>\n      <th>16298</th>\n      <td>Q9ZVR3</td>\n      <td>reviewed</td>\n      <td>PP2B4_ARATH</td>\n      <td>NaN</td>\n      <td>MNTQILSQKTRYSAYIVYKTIYRFHGFKHIGVGFIGHGTPKAKRWE...</td>\n    </tr>\n    <tr>\n      <th>16299</th>\n      <td>Q9ZW38</td>\n      <td>reviewed</td>\n      <td>FBK36_ARATH</td>\n      <td>NaN</td>\n      <td>MASISETSDDGSNGGDPNQKPEEPHKNPQEGKEEENQNEKPKEDDH...</td>\n    </tr>\n    <tr>\n      <th>16300</th>\n      <td>Q9ZWC6</td>\n      <td>reviewed</td>\n      <td>ATB_ARATH</td>\n      <td>NaN</td>\n      <td>MEEVTRSVLAEEILKRLDLENLCSVACVSTTLRSAVVSGVLPSLTS...</td>\n    </tr>\n  </tbody>\n</table>\n<p>16301 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Nice! Now we have some proteins and their subcellular locations. Let's start filtering this down. First, let's remove the columns without subcellular location information.","metadata":{"id":"0bcdf34b"}},{"cell_type":"code","source":"df = df.dropna()  # Drop proteins with missing columns\ndf","metadata":{"id":"31d87663","execution":{"iopub.status.busy":"2023-11-28T04:51:04.816955Z","iopub.execute_input":"2023-11-28T04:51:04.817346Z","iopub.status.idle":"2023-11-28T04:51:04.847558Z","shell.execute_reply.started":"2023-11-28T04:51:04.817312Z","shell.execute_reply":"2023-11-28T04:51:04.846600Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"            Entry  Reviewed   Entry Name  \\\n0      A0A0A7EPL0  reviewed  PIAL1_ARATH   \n1      A0A178VEK7  reviewed   DUO1_ARATH   \n2      A0A178WF56  reviewed  CSTM3_ARATH   \n3      A0A1I9LMX5  reviewed  PCEP9_ARATH   \n4      A0A1I9LN01  reviewed   LAF3_ARATH   \n...           ...       ...          ...   \n16242      Q9SYZ7  reviewed  U496A_ARATH   \n16259      Q9XIK5  reviewed  Y1045_ARATH   \n16273      Q9ZU26  reviewed  Y1197_ARATH   \n16275      Q9ZU96  reviewed  Y2168_ARATH   \n16284      Q9ZUU2  reviewed  PXL2C_ARATH   \n\n                               Subcellular location [CC]  \\\n0           SUBCELLULAR LOCATION: Nucleus {ECO:0000305}.   \n1      SUBCELLULAR LOCATION: Nucleus {ECO:0000255|PRO...   \n2      SUBCELLULAR LOCATION: Cell membrane {ECO:00002...   \n3      SUBCELLULAR LOCATION: [C-terminally encoded pe...   \n4      SUBCELLULAR LOCATION: Membrane {ECO:0000255}; ...   \n...                                                  ...   \n16242  SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...   \n16259       SUBCELLULAR LOCATION: Nucleus {ECO:0000250}.   \n16273       SUBCELLULAR LOCATION: Nucleus {ECO:0000250}.   \n16275  SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...   \n16284  SUBCELLULAR LOCATION: Plastid, chloroplast {EC...   \n\n                                                Sequence  \n0      MVIPATSRFGFRAEFNTKEFQASCISLANEIDAAIGRNEVPGNIQE...  \n1      MRKMEAKKEEIKKGPWKAEEDEVLINHVKRYGPRDWSSIRSKGLLQ...  \n2      MAQYHQQHEMKQTMAETQYVTAPPPMGYPVMMKDSPQTVQPPHEGQ...  \n3      MKLLSITLTSIVISMVFYQTPITTEARSLRKTNDQDHFKAGFTDDF...  \n4      MTGWYEFPVMIGFVSAAVFLLISVAYLPLLNDLYWSTLKSLTPPAG...  \n...                                                  ...  \n16242  MGNQTSKKSQETSAKSVHYTTELRSYAAACKADTELQSFDTCLQAR...  \n16259  MAQNKNLNLELSLSQYVEDDPWVLKKKLSDSDLYYSAQLYLPKQEM...  \n16273  MAQELDLELGLAPYDPWVLKKNLTESDLNNGFIILPKQDFEKIIRQ...  \n16275  MEMKQMKFLTHQAFFSSVRSGDLSQLQQLVDNLTGDELIDESSPCS...  \n16284  MAIALSSSSTITSITLQPKLKTIHGLGTVLPGYSVKSHFRSVSLRR...  \n\n[12408 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Entry</th>\n      <th>Reviewed</th>\n      <th>Entry Name</th>\n      <th>Subcellular location [CC]</th>\n      <th>Sequence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A0A0A7EPL0</td>\n      <td>reviewed</td>\n      <td>PIAL1_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000305}.</td>\n      <td>MVIPATSRFGFRAEFNTKEFQASCISLANEIDAAIGRNEVPGNIQE...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A0A178VEK7</td>\n      <td>reviewed</td>\n      <td>DUO1_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000255|PRO...</td>\n      <td>MRKMEAKKEEIKKGPWKAEEDEVLINHVKRYGPRDWSSIRSKGLLQ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A0A178WF56</td>\n      <td>reviewed</td>\n      <td>CSTM3_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Cell membrane {ECO:00002...</td>\n      <td>MAQYHQQHEMKQTMAETQYVTAPPPMGYPVMMKDSPQTVQPPHEGQ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0A1I9LMX5</td>\n      <td>reviewed</td>\n      <td>PCEP9_ARATH</td>\n      <td>SUBCELLULAR LOCATION: [C-terminally encoded pe...</td>\n      <td>MKLLSITLTSIVISMVFYQTPITTEARSLRKTNDQDHFKAGFTDDF...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A0A1I9LN01</td>\n      <td>reviewed</td>\n      <td>LAF3_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000255}; ...</td>\n      <td>MTGWYEFPVMIGFVSAAVFLLISVAYLPLLNDLYWSTLKSLTPPAG...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16242</th>\n      <td>Q9SYZ7</td>\n      <td>reviewed</td>\n      <td>U496A_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...</td>\n      <td>MGNQTSKKSQETSAKSVHYTTELRSYAAACKADTELQSFDTCLQAR...</td>\n    </tr>\n    <tr>\n      <th>16259</th>\n      <td>Q9XIK5</td>\n      <td>reviewed</td>\n      <td>Y1045_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000250}.</td>\n      <td>MAQNKNLNLELSLSQYVEDDPWVLKKKLSDSDLYYSAQLYLPKQEM...</td>\n    </tr>\n    <tr>\n      <th>16273</th>\n      <td>Q9ZU26</td>\n      <td>reviewed</td>\n      <td>Y1197_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000250}.</td>\n      <td>MAQELDLELGLAPYDPWVLKKNLTESDLNNGFIILPKQDFEKIIRQ...</td>\n    </tr>\n    <tr>\n      <th>16275</th>\n      <td>Q9ZU96</td>\n      <td>reviewed</td>\n      <td>Y2168_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...</td>\n      <td>MEMKQMKFLTHQAFFSSVRSGDLSQLQQLVDNLTGDELIDESSPCS...</td>\n    </tr>\n    <tr>\n      <th>16284</th>\n      <td>Q9ZUU2</td>\n      <td>reviewed</td>\n      <td>PXL2C_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Plastid, chloroplast {EC...</td>\n      <td>MAIALSSSSTITSITLQPKLKTIHGLGTVLPGYSVKSHFRSVSLRR...</td>\n    </tr>\n  </tbody>\n</table>\n<p>12408 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df[df['Sequence'].apply(lambda x: len(x) < 512)]  #drop sequences with length larger than 512 [Because of Data limit issues]\ndf","metadata":{"execution":{"iopub.status.busy":"2023-11-28T04:51:07.508218Z","iopub.execute_input":"2023-11-28T04:51:07.509209Z","iopub.status.idle":"2023-11-28T04:51:07.537645Z","shell.execute_reply.started":"2023-11-28T04:51:07.509159Z","shell.execute_reply":"2023-11-28T04:51:07.536367Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"            Entry  Reviewed   Entry Name  \\\n1      A0A178VEK7  reviewed   DUO1_ARATH   \n2      A0A178WF56  reviewed  CSTM3_ARATH   \n3      A0A1I9LMX5  reviewed  PCEP9_ARATH   \n5      A0A1P8AQ95  reviewed  STMP4_ARATH   \n9          A0JQ18  reviewed  SOP14_ARATH   \n...           ...       ...          ...   \n16241      Q9SYL8  reviewed  Y1786_ARATH   \n16242      Q9SYZ7  reviewed  U496A_ARATH   \n16259      Q9XIK5  reviewed  Y1045_ARATH   \n16273      Q9ZU26  reviewed  Y1197_ARATH   \n16284      Q9ZUU2  reviewed  PXL2C_ARATH   \n\n                               Subcellular location [CC]  \\\n1      SUBCELLULAR LOCATION: Nucleus {ECO:0000255|PRO...   \n2      SUBCELLULAR LOCATION: Cell membrane {ECO:00002...   \n3      SUBCELLULAR LOCATION: [C-terminally encoded pe...   \n5      SUBCELLULAR LOCATION: Cell membrane {ECO:00002...   \n9      SUBCELLULAR LOCATION: Cell membrane {ECO:00002...   \n...                                                  ...   \n16241       SUBCELLULAR LOCATION: Nucleus {ECO:0000250}.   \n16242  SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...   \n16259       SUBCELLULAR LOCATION: Nucleus {ECO:0000250}.   \n16273       SUBCELLULAR LOCATION: Nucleus {ECO:0000250}.   \n16284  SUBCELLULAR LOCATION: Plastid, chloroplast {EC...   \n\n                                                Sequence  \n1      MRKMEAKKEEIKKGPWKAEEDEVLINHVKRYGPRDWSSIRSKGLLQ...  \n2      MAQYHQQHEMKQTMAETQYVTAPPPMGYPVMMKDSPQTVQPPHEGQ...  \n3      MKLLSITLTSIVISMVFYQTPITTEARSLRKTNDQDHFKAGFTDDF...  \n5      MTKNMTKKKMGLMSPNIAAFVLPMLLVLFTISSQVEVVESTGRKLS...  \n9      MAAKTSNLVALLLSLFLLLLSISSQVGLGEAKRNLRNNLRLDCVSH...  \n...                                                  ...  \n16241  MAEEQREISHENNVSLGSAETAIPLTNVSISPTKKEEQKTVYLVLF...  \n16242  MGNQTSKKSQETSAKSVHYTTELRSYAAACKADTELQSFDTCLQAR...  \n16259  MAQNKNLNLELSLSQYVEDDPWVLKKKLSDSDLYYSAQLYLPKQEM...  \n16273  MAQELDLELGLAPYDPWVLKKNLTESDLNNGFIILPKQDFEKIIRQ...  \n16284  MAIALSSSSTITSITLQPKLKTIHGLGTVLPGYSVKSHFRSVSLRR...  \n\n[8308 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Entry</th>\n      <th>Reviewed</th>\n      <th>Entry Name</th>\n      <th>Subcellular location [CC]</th>\n      <th>Sequence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>A0A178VEK7</td>\n      <td>reviewed</td>\n      <td>DUO1_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000255|PRO...</td>\n      <td>MRKMEAKKEEIKKGPWKAEEDEVLINHVKRYGPRDWSSIRSKGLLQ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A0A178WF56</td>\n      <td>reviewed</td>\n      <td>CSTM3_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Cell membrane {ECO:00002...</td>\n      <td>MAQYHQQHEMKQTMAETQYVTAPPPMGYPVMMKDSPQTVQPPHEGQ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0A1I9LMX5</td>\n      <td>reviewed</td>\n      <td>PCEP9_ARATH</td>\n      <td>SUBCELLULAR LOCATION: [C-terminally encoded pe...</td>\n      <td>MKLLSITLTSIVISMVFYQTPITTEARSLRKTNDQDHFKAGFTDDF...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>A0A1P8AQ95</td>\n      <td>reviewed</td>\n      <td>STMP4_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Cell membrane {ECO:00002...</td>\n      <td>MTKNMTKKKMGLMSPNIAAFVLPMLLVLFTISSQVEVVESTGRKLS...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>A0JQ18</td>\n      <td>reviewed</td>\n      <td>SOP14_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Cell membrane {ECO:00002...</td>\n      <td>MAAKTSNLVALLLSLFLLLLSISSQVGLGEAKRNLRNNLRLDCVSH...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16241</th>\n      <td>Q9SYL8</td>\n      <td>reviewed</td>\n      <td>Y1786_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000250}.</td>\n      <td>MAEEQREISHENNVSLGSAETAIPLTNVSISPTKKEEQKTVYLVLF...</td>\n    </tr>\n    <tr>\n      <th>16242</th>\n      <td>Q9SYZ7</td>\n      <td>reviewed</td>\n      <td>U496A_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...</td>\n      <td>MGNQTSKKSQETSAKSVHYTTELRSYAAACKADTELQSFDTCLQAR...</td>\n    </tr>\n    <tr>\n      <th>16259</th>\n      <td>Q9XIK5</td>\n      <td>reviewed</td>\n      <td>Y1045_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000250}.</td>\n      <td>MAQNKNLNLELSLSQYVEDDPWVLKKKLSDSDLYYSAQLYLPKQEM...</td>\n    </tr>\n    <tr>\n      <th>16273</th>\n      <td>Q9ZU26</td>\n      <td>reviewed</td>\n      <td>Y1197_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000250}.</td>\n      <td>MAQELDLELGLAPYDPWVLKKNLTESDLNNGFIILPKQDFEKIIRQ...</td>\n    </tr>\n    <tr>\n      <th>16284</th>\n      <td>Q9ZUU2</td>\n      <td>reviewed</td>\n      <td>PXL2C_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Plastid, chloroplast {EC...</td>\n      <td>MAIALSSSSTITSITLQPKLKTIHGLGTVLPGYSVKSHFRSVSLRR...</td>\n    </tr>\n  </tbody>\n</table>\n<p>8308 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# saving the dataframe\ndf.to_csv('UneditedDataUniprotProteins.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-28T04:51:11.440152Z","iopub.execute_input":"2023-11-28T04:51:11.440992Z","iopub.status.idle":"2023-11-28T04:51:11.635058Z","shell.execute_reply.started":"2023-11-28T04:51:11.440954Z","shell.execute_reply":"2023-11-28T04:51:11.634016Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Now we'll make one dataframe of proteins that contain `Chloroplast` in their subcellular localization column, and a second that does not mention `Chloroplast`. ","metadata":{"id":"10d1af5c"}},{"cell_type":"code","source":"chloroplastic = df['Subcellular location [CC]'].str.contains(\"chloroplast\")\n","metadata":{"id":"c831bb16","execution":{"iopub.status.busy":"2023-11-28T04:51:13.311498Z","iopub.execute_input":"2023-11-28T04:51:13.311891Z","iopub.status.idle":"2023-11-28T04:51:13.326684Z","shell.execute_reply.started":"2023-11-28T04:51:13.311860Z","shell.execute_reply":"2023-11-28T04:51:13.325428Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"chloroplastic_df = df[chloroplastic]\nchloroplastic_df","metadata":{"id":"f41139a2","outputId":"82722b56-07b6-4071-eb54-59cf33860a5e","execution":{"iopub.status.busy":"2023-11-28T04:51:15.332882Z","iopub.execute_input":"2023-11-28T04:51:15.333265Z","iopub.status.idle":"2023-11-28T04:51:15.351502Z","shell.execute_reply.started":"2023-11-28T04:51:15.333234Z","shell.execute_reply":"2023-11-28T04:51:15.350330Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"        Entry  Reviewed   Entry Name  \\\n12     A1A6H3  reviewed   RBSK_ARATH   \n13     A1A6M1  reviewed  PTAC5_ARATH   \n17     A2RVM0  reviewed  TIC32_ARATH   \n70     B9DFK5  reviewed  RETIC_ARATH   \n74     B9DFZ0  reviewed   NTH2_ARATH   \n...       ...       ...          ...   \n15147  Q9SSR1  reviewed  Y1259_ARATH   \n15221  Q9SW33  reviewed   TL1Y_ARATH   \n15419  Q9ZW12  reviewed  TRNH5_ARATH   \n16220  Q9STN5  reviewed  Y4833_ARATH   \n16284  Q9ZUU2  reviewed  PXL2C_ARATH   \n\n                               Subcellular location [CC]  \\\n12     SUBCELLULAR LOCATION: Plastid, chloroplast str...   \n13     SUBCELLULAR LOCATION: Plastid, chloroplast str...   \n17     SUBCELLULAR LOCATION: Plastid, chloroplast inn...   \n70     SUBCELLULAR LOCATION: Plastid, chloroplast mem...   \n74     SUBCELLULAR LOCATION: Plastid, chloroplast str...   \n...                                                  ...   \n15147  SUBCELLULAR LOCATION: Plastid, chloroplast {EC...   \n15221  SUBCELLULAR LOCATION: Plastid, chloroplast thy...   \n15419  SUBCELLULAR LOCATION: Plastid, chloroplast {EC...   \n16220  SUBCELLULAR LOCATION: Plastid, chloroplast {EC...   \n16284  SUBCELLULAR LOCATION: Plastid, chloroplast {EC...   \n\n                                                Sequence  \n12     MMKGISSVSQSINYNPYIEFNRPQLQISTVNPNPAQSRFSRPRSLR...  \n13     MASSSLPLSLPFPLRSLTSTTRSLPFQCSPLFFSIPSSIVCFSTQN...  \n17     MWFFGSKGASGFSSRSTAEEVTHGVDGTGLTAIVTGASSGIGVETA...  \n70     MAGCAMNLQFSSVVKVRNEISSFGICNRDFVFRDLAKAMKVPVLRI...  \n74     MILTGAASTFPIVARVLNAMNRRMYAATTLSSAKSISAESLNLRSD...  \n...                                                  ...  \n15147  MAILIPASFGRLTITSRAQVRVRVSASANQRTIRRDSVDWVKETSS...  \n15221  MSLVASLQLILPPRPRSTKLLCSLQSPKQEQELSSTSPPISLLPKL...  \n15419  MVLDMASHLYTNPPQNLHFISSSSSLKPHLCLSFKRINPKHKSSSS...  \n16220  MERSASVGVNDGRFGGNQFYSPSFSSSSSSSSMRHVNYSCGSCGYE...  \n16284  MAIALSSSSTITSITLQPKLKTIHGLGTVLPGYSVKSHFRSVSLRR...  \n\n[1064 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Entry</th>\n      <th>Reviewed</th>\n      <th>Entry Name</th>\n      <th>Subcellular location [CC]</th>\n      <th>Sequence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>A1A6H3</td>\n      <td>reviewed</td>\n      <td>RBSK_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Plastid, chloroplast str...</td>\n      <td>MMKGISSVSQSINYNPYIEFNRPQLQISTVNPNPAQSRFSRPRSLR...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>A1A6M1</td>\n      <td>reviewed</td>\n      <td>PTAC5_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Plastid, chloroplast str...</td>\n      <td>MASSSLPLSLPFPLRSLTSTTRSLPFQCSPLFFSIPSSIVCFSTQN...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>A2RVM0</td>\n      <td>reviewed</td>\n      <td>TIC32_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Plastid, chloroplast inn...</td>\n      <td>MWFFGSKGASGFSSRSTAEEVTHGVDGTGLTAIVTGASSGIGVETA...</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>B9DFK5</td>\n      <td>reviewed</td>\n      <td>RETIC_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Plastid, chloroplast mem...</td>\n      <td>MAGCAMNLQFSSVVKVRNEISSFGICNRDFVFRDLAKAMKVPVLRI...</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>B9DFZ0</td>\n      <td>reviewed</td>\n      <td>NTH2_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Plastid, chloroplast str...</td>\n      <td>MILTGAASTFPIVARVLNAMNRRMYAATTLSSAKSISAESLNLRSD...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15147</th>\n      <td>Q9SSR1</td>\n      <td>reviewed</td>\n      <td>Y1259_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Plastid, chloroplast {EC...</td>\n      <td>MAILIPASFGRLTITSRAQVRVRVSASANQRTIRRDSVDWVKETSS...</td>\n    </tr>\n    <tr>\n      <th>15221</th>\n      <td>Q9SW33</td>\n      <td>reviewed</td>\n      <td>TL1Y_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Plastid, chloroplast thy...</td>\n      <td>MSLVASLQLILPPRPRSTKLLCSLQSPKQEQELSSTSPPISLLPKL...</td>\n    </tr>\n    <tr>\n      <th>15419</th>\n      <td>Q9ZW12</td>\n      <td>reviewed</td>\n      <td>TRNH5_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Plastid, chloroplast {EC...</td>\n      <td>MVLDMASHLYTNPPQNLHFISSSSSLKPHLCLSFKRINPKHKSSSS...</td>\n    </tr>\n    <tr>\n      <th>16220</th>\n      <td>Q9STN5</td>\n      <td>reviewed</td>\n      <td>Y4833_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Plastid, chloroplast {EC...</td>\n      <td>MERSASVGVNDGRFGGNQFYSPSFSSSSSSSSMRHVNYSCGSCGYE...</td>\n    </tr>\n    <tr>\n      <th>16284</th>\n      <td>Q9ZUU2</td>\n      <td>reviewed</td>\n      <td>PXL2C_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Plastid, chloroplast {EC...</td>\n      <td>MAIALSSSSTITSITLQPKLKTIHGLGTVLPGYSVKSHFRSVSLRR...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1064 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"chloroplastic_non_df = df[~chloroplastic]\nchloroplastic_non_df","metadata":{"id":"be5c420e","outputId":"a64fcb81-c0b1-4126-a12f-7523cb384e70","execution":{"iopub.status.busy":"2023-11-28T04:51:17.837078Z","iopub.execute_input":"2023-11-28T04:51:17.837492Z","iopub.status.idle":"2023-11-28T04:51:17.856105Z","shell.execute_reply.started":"2023-11-28T04:51:17.837461Z","shell.execute_reply":"2023-11-28T04:51:17.855043Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"            Entry  Reviewed   Entry Name  \\\n1      A0A178VEK7  reviewed   DUO1_ARATH   \n2      A0A178WF56  reviewed  CSTM3_ARATH   \n3      A0A1I9LMX5  reviewed  PCEP9_ARATH   \n5      A0A1P8AQ95  reviewed  STMP4_ARATH   \n9          A0JQ18  reviewed  SOP14_ARATH   \n...           ...       ...          ...   \n16237      Q9SYB0  reviewed  TAUE2_ARATH   \n16241      Q9SYL8  reviewed  Y1786_ARATH   \n16242      Q9SYZ7  reviewed  U496A_ARATH   \n16259      Q9XIK5  reviewed  Y1045_ARATH   \n16273      Q9ZU26  reviewed  Y1197_ARATH   \n\n                               Subcellular location [CC]  \\\n1      SUBCELLULAR LOCATION: Nucleus {ECO:0000255|PRO...   \n2      SUBCELLULAR LOCATION: Cell membrane {ECO:00002...   \n3      SUBCELLULAR LOCATION: [C-terminally encoded pe...   \n5      SUBCELLULAR LOCATION: Cell membrane {ECO:00002...   \n9      SUBCELLULAR LOCATION: Cell membrane {ECO:00002...   \n...                                                  ...   \n16237  SUBCELLULAR LOCATION: Membrane {ECO:0000255}; ...   \n16241       SUBCELLULAR LOCATION: Nucleus {ECO:0000250}.   \n16242  SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...   \n16259       SUBCELLULAR LOCATION: Nucleus {ECO:0000250}.   \n16273       SUBCELLULAR LOCATION: Nucleus {ECO:0000250}.   \n\n                                                Sequence  \n1      MRKMEAKKEEIKKGPWKAEEDEVLINHVKRYGPRDWSSIRSKGLLQ...  \n2      MAQYHQQHEMKQTMAETQYVTAPPPMGYPVMMKDSPQTVQPPHEGQ...  \n3      MKLLSITLTSIVISMVFYQTPITTEARSLRKTNDQDHFKAGFTDDF...  \n5      MTKNMTKKKMGLMSPNIAAFVLPMLLVLFTISSQVEVVESTGRKLS...  \n9      MAAKTSNLVALLLSLFLLLLSISSQVGLGEAKRNLRNNLRLDCVSH...  \n...                                                  ...  \n16237  MRNNFVPIILSFIIFLTPSIAEQEPSILSPVDQLLNKTSSYLDFST...  \n16241  MAEEQREISHENNVSLGSAETAIPLTNVSISPTKKEEQKTVYLVLF...  \n16242  MGNQTSKKSQETSAKSVHYTTELRSYAAACKADTELQSFDTCLQAR...  \n16259  MAQNKNLNLELSLSQYVEDDPWVLKKKLSDSDLYYSAQLYLPKQEM...  \n16273  MAQELDLELGLAPYDPWVLKKNLTESDLNNGFIILPKQDFEKIIRQ...  \n\n[7244 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Entry</th>\n      <th>Reviewed</th>\n      <th>Entry Name</th>\n      <th>Subcellular location [CC]</th>\n      <th>Sequence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>A0A178VEK7</td>\n      <td>reviewed</td>\n      <td>DUO1_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000255|PRO...</td>\n      <td>MRKMEAKKEEIKKGPWKAEEDEVLINHVKRYGPRDWSSIRSKGLLQ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A0A178WF56</td>\n      <td>reviewed</td>\n      <td>CSTM3_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Cell membrane {ECO:00002...</td>\n      <td>MAQYHQQHEMKQTMAETQYVTAPPPMGYPVMMKDSPQTVQPPHEGQ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0A1I9LMX5</td>\n      <td>reviewed</td>\n      <td>PCEP9_ARATH</td>\n      <td>SUBCELLULAR LOCATION: [C-terminally encoded pe...</td>\n      <td>MKLLSITLTSIVISMVFYQTPITTEARSLRKTNDQDHFKAGFTDDF...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>A0A1P8AQ95</td>\n      <td>reviewed</td>\n      <td>STMP4_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Cell membrane {ECO:00002...</td>\n      <td>MTKNMTKKKMGLMSPNIAAFVLPMLLVLFTISSQVEVVESTGRKLS...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>A0JQ18</td>\n      <td>reviewed</td>\n      <td>SOP14_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Cell membrane {ECO:00002...</td>\n      <td>MAAKTSNLVALLLSLFLLLLSISSQVGLGEAKRNLRNNLRLDCVSH...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16237</th>\n      <td>Q9SYB0</td>\n      <td>reviewed</td>\n      <td>TAUE2_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000255}; ...</td>\n      <td>MRNNFVPIILSFIIFLTPSIAEQEPSILSPVDQLLNKTSSYLDFST...</td>\n    </tr>\n    <tr>\n      <th>16241</th>\n      <td>Q9SYL8</td>\n      <td>reviewed</td>\n      <td>Y1786_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000250}.</td>\n      <td>MAEEQREISHENNVSLGSAETAIPLTNVSISPTKKEEQKTVYLVLF...</td>\n    </tr>\n    <tr>\n      <th>16242</th>\n      <td>Q9SYZ7</td>\n      <td>reviewed</td>\n      <td>U496A_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Membrane {ECO:0000305}; ...</td>\n      <td>MGNQTSKKSQETSAKSVHYTTELRSYAAACKADTELQSFDTCLQAR...</td>\n    </tr>\n    <tr>\n      <th>16259</th>\n      <td>Q9XIK5</td>\n      <td>reviewed</td>\n      <td>Y1045_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000250}.</td>\n      <td>MAQNKNLNLELSLSQYVEDDPWVLKKKLSDSDLYYSAQLYLPKQEM...</td>\n    </tr>\n    <tr>\n      <th>16273</th>\n      <td>Q9ZU26</td>\n      <td>reviewed</td>\n      <td>Y1197_ARATH</td>\n      <td>SUBCELLULAR LOCATION: Nucleus {ECO:0000250}.</td>\n      <td>MAQELDLELGLAPYDPWVLKKNLTESDLNNGFIILPKQDFEKIIRQ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>7244 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We're almost done! Now, let's make a list of sequences from each df and generate the associated labels. We'll use `1` as the label for Chloroplast proteins and `0` as the label for the rest of the remaining proteins.","metadata":{"id":"77e8cea6"}},{"cell_type":"code","source":"chloroplastic_sequences = chloroplastic_df[\"Sequence\"].tolist()\nchloroplastic_labels = [1 for protein in chloroplastic_sequences]","metadata":{"id":"023ec31b","execution":{"iopub.status.busy":"2023-11-28T04:51:20.335546Z","iopub.execute_input":"2023-11-28T04:51:20.336278Z","iopub.status.idle":"2023-11-28T04:51:20.341133Z","shell.execute_reply.started":"2023-11-28T04:51:20.336243Z","shell.execute_reply":"2023-11-28T04:51:20.340180Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"chloroplastic_non_df_sequences = chloroplastic_non_df[\"Sequence\"].tolist()\nchloroplastic_non_df_labels = [0 for protein in chloroplastic_non_df_sequences]","metadata":{"id":"d0e7318b","execution":{"iopub.status.busy":"2023-11-28T04:51:22.712354Z","iopub.execute_input":"2023-11-28T04:51:22.713136Z","iopub.status.idle":"2023-11-28T04:51:22.718605Z","shell.execute_reply.started":"2023-11-28T04:51:22.713100Z","shell.execute_reply":"2023-11-28T04:51:22.717394Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Now we can concatenate these lists together to get the `sequences` and `labels` lists that will form our final training data. ","metadata":{"id":"5a4bbda2"}},{"cell_type":"code","source":"sequences = chloroplastic_sequences + chloroplastic_non_df_sequences\nlabels = chloroplastic_labels + chloroplastic_non_df_labels\n\n# Quick check to make sure we got it right\nlen(sequences) == len(labels)","metadata":{"id":"7dec7a4a","outputId":"44b8e567-c513-4e99-8ba9-11a85a1525cc","execution":{"iopub.status.busy":"2023-11-28T04:51:24.729166Z","iopub.execute_input":"2023-11-28T04:51:24.729562Z","iopub.status.idle":"2023-11-28T04:51:24.739243Z","shell.execute_reply.started":"2023-11-28T04:51:24.729532Z","shell.execute_reply":"2023-11-28T04:51:24.738255Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"### If all is correct till here then we can say that our data is loaded correctly","metadata":{"id":"bc782dd0"}},{"cell_type":"markdown","source":"## Splitting the data","metadata":{"id":"e0aac39c"}},{"cell_type":"markdown","source":"Since the data we're loading isn't prepared for us as a machine learning dataset, we'll have to split the data into train and test sets. We can use sklearn's function for that:","metadata":{"id":"a9099e7c"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_sequences, test_sequences, train_labels, test_labels = train_test_split(sequences, labels, test_size=0.25, shuffle=True)","metadata":{"id":"366147ad","execution":{"iopub.status.busy":"2023-11-28T04:51:27.506394Z","iopub.execute_input":"2023-11-28T04:51:27.507099Z","iopub.status.idle":"2023-11-28T04:51:27.518093Z","shell.execute_reply.started":"2023-11-28T04:51:27.507062Z","shell.execute_reply":"2023-11-28T04:51:27.517107Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Tokenizing the data","metadata":{"id":"7d29b4ed"}},{"cell_type":"markdown","source":"All inputs to neural nets must be numerical. The process of converting strings into numerical indices suitable for a neural net is called **tokenization**. For natural language this can be quite complex, as usually the network's vocabulary will not contain every possible word, which means the tokenizer must handle splitting rarer words into pieces, as well as all the complexities of capitalization and unicode characters and so on.\n\nWith proteins, however, things are very easy. In protein language models, each amino acid is converted to a single token. Every model on `transformers` comes with an associated `tokenizer` that handles tokenization for it, and protein language models are no different.","metadata":{"id":"c02baaf7"}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"id":"ddbe2b2d","outputId":"250d8506-4f6a-490c-bb90-dfb80c0ec9bc","execution":{"iopub.status.busy":"2023-11-28T04:51:30.049304Z","iopub.execute_input":"2023-11-28T04:51:30.050357Z","iopub.status.idle":"2023-11-28T04:51:30.573230Z","shell.execute_reply.started":"2023-11-28T04:51:30.050308Z","shell.execute_reply":"2023-11-28T04:51:30.572245Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/95.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcb7c94de7a340c99e5cbcf94d1bb393"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading vocab.txt:   0%|          | 0.00/93.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"689657aa46ae4b61b3cfcd83c117804b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3aa06a2219c34bbb949f940eaf52beeb"}},"metadata":{}}]},{"cell_type":"markdown","source":"Let's try a single sequence to see what the outputs from our tokenizer look like:","metadata":{"id":"9d16be37"}},{"cell_type":"code","source":"tokenizer(train_sequences[0])","metadata":{"id":"687386af","outputId":"f3c6b0cc-fdd8-4dcb-c92e-aeb4e9b1cd0f","execution":{"iopub.status.busy":"2023-11-28T04:51:33.453201Z","iopub.execute_input":"2023-11-28T04:51:33.453695Z","iopub.status.idle":"2023-11-28T04:51:33.463848Z","shell.execute_reply.started":"2023-11-28T04:51:33.453641Z","shell.execute_reply":"2023-11-28T04:51:33.462654Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [0, 20, 8, 18, 17, 15, 7, 14, 17, 12, 14, 6, 5, 14, 5, 4, 8, 5, 4, 4, 15, 7, 8, 7, 12, 6, 6, 4, 6, 7, 19, 5, 4, 11, 17, 8, 4, 19, 17, 7, 13, 6, 6, 21, 10, 5, 7, 20, 18, 17, 10, 4, 11, 6, 12, 15, 9, 15, 7, 19, 14, 9, 6, 11, 21, 18, 20, 7, 14, 22, 18, 9, 10, 14, 12, 12, 19, 13, 7, 10, 5, 10, 14, 19, 4, 7, 9, 8, 11, 11, 6, 8, 21, 13, 4, 16, 20, 7, 15, 12, 6, 4, 10, 7, 4, 11, 10, 14, 20, 6, 13, 10, 4, 14, 16, 12, 19, 10, 11, 4, 6, 9, 17, 19, 8, 9, 10, 7, 4, 14, 8, 12, 12, 21, 9, 11, 4, 15, 5, 7, 7, 5, 16, 19, 17, 5, 8, 16, 4, 12, 11, 16, 10, 9, 5, 7, 8, 10, 9, 12, 10, 15, 12, 4, 11, 9, 10, 5, 8, 17, 18, 13, 12, 5, 4, 13, 13, 7, 8, 12, 11, 11, 4, 11, 18, 6, 15, 9, 18, 11, 5, 5, 12, 9, 5, 15, 16, 7, 5, 5, 16, 9, 5, 9, 10, 5, 15, 18, 12, 7, 9, 15, 5, 9, 16, 13, 10, 10, 8, 5, 7, 12, 10, 5, 16, 6, 9, 5, 15, 8, 5, 16, 4, 12, 6, 16, 5, 12, 5, 17, 17, 16, 5, 18, 12, 11, 4, 10, 15, 12, 9, 5, 5, 10, 9, 12, 5, 16, 11, 12, 5, 16, 8, 5, 17, 15, 7, 19, 4, 8, 8, 17, 13, 4, 4, 4, 17, 4, 16, 9, 20, 17, 4, 9, 14, 15, 15, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"markdown","source":"This looks good! We can see that our sequence has been converted into `input_ids`, which is the tokenized sequence, and an `attention_mask`. The attention mask handles the case when we have sequences of variable length - in those cases, the shorter sequences are padded with blank \"padding\" tokens, and the attention mask is padded with 0s to indicate that those tokens should be ignored by the model.\n\nSo now, let's tokenize our whole dataset. Note that we don't need to do anything with the labels, as they're already in the format we need.","metadata":{"id":"9a719808"}},{"cell_type":"code","source":"train_tokenized = tokenizer(train_sequences)\ntest_tokenized = tokenizer(test_sequences)\nprint(\"Tokenisation Successfull\")","metadata":{"id":"56e26ddf","execution":{"iopub.status.busy":"2023-11-28T04:51:35.705792Z","iopub.execute_input":"2023-11-28T04:51:35.706579Z","iopub.status.idle":"2023-11-28T04:51:46.265178Z","shell.execute_reply.started":"2023-11-28T04:51:35.706540Z","shell.execute_reply":"2023-11-28T04:51:46.263956Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Tokenisation Successfull\n","output_type":"stream"}]},{"cell_type":"markdown","source":"If indexing error pops up , reduce the length of the sequences to feed in","metadata":{}},{"cell_type":"markdown","source":"## Dataset creation","metadata":{"id":"df3681d1"}},{"cell_type":"markdown","source":"Now we want to turn this data into a dataset that PyTorch can load samples from. We can use the HuggingFace `Dataset` class for this","metadata":{"id":"85089e49"}},{"cell_type":"code","source":"from datasets import Dataset\ntrain_dataset = Dataset.from_dict(train_tokenized)\ntest_dataset = Dataset.from_dict(test_tokenized)\n\ntrain_dataset","metadata":{"id":"fb79ba6c","outputId":"b8148264-c6f5-439b-ef6b-f67dd764d288","execution":{"iopub.status.busy":"2023-11-28T04:51:49.047985Z","iopub.execute_input":"2023-11-28T04:51:49.048835Z","iopub.status.idle":"2023-11-28T04:51:49.944852Z","shell.execute_reply.started":"2023-11-28T04:51:49.048800Z","shell.execute_reply":"2023-11-28T04:51:49.944011Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask'],\n    num_rows: 6231\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"Labels are yet to be added to our dataset , so we will add them now!","metadata":{"id":"9e809e47"}},{"cell_type":"code","source":"train_dataset = train_dataset.add_column(\"labels\", train_labels)\ntest_dataset = test_dataset.add_column(\"labels\", test_labels)\ntrain_dataset\ntest_dataset","metadata":{"id":"090acc0d","outputId":"dfc747d8-411c-4b1a-c25a-269726730a6a","execution":{"iopub.status.busy":"2023-11-28T04:51:51.818026Z","iopub.execute_input":"2023-11-28T04:51:51.818441Z","iopub.status.idle":"2023-11-28T04:51:51.873100Z","shell.execute_reply.started":"2023-11-28T04:51:51.818411Z","shell.execute_reply":"2023-11-28T04:51:51.871915Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask', 'labels'],\n    num_rows: 2077\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"### If all correct till here we can move forward with finetuning the model","metadata":{"id":"ced9aaa8"}},{"cell_type":"markdown","source":"## Model loading","metadata":{"id":"af074a5c"}},{"cell_type":"markdown","source":"If everything is done correctly this should run without any problems","metadata":{"id":"ccab5d70"}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n\nnum_labels = max(train_labels + test_labels) + 1  # Add 1 since 0 can be a label\nmodel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)","metadata":{"id":"fc164b49","outputId":"8ba88260-bc17-470c-a49e-0e9de7ba1789","execution":{"iopub.status.busy":"2023-11-28T04:51:54.881311Z","iopub.execute_input":"2023-11-28T04:51:54.881777Z","iopub.status.idle":"2023-11-28T04:51:58.815391Z","shell.execute_reply.started":"2023-11-28T04:51:54.881736Z","shell.execute_reply":"2023-11-28T04:51:58.814672Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/778 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2ea59f31d8d4e3aa5adcad7da876456"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/136M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"488b06572d564b59a08b1f9b1a86a059"}},"metadata":{}},{"name":"stderr","text":"Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"These warnings are telling us that the model is discarding some weights that it used for language modelling (the `lm_head`) and adding some weights for sequence classification (the `classifier`). This is exactly what we expect when we want to fine-tune a language model on a sequence classification task.\nSo we will be ignoring them.\n\nNext, we initialize our `TrainingArguments`. These control the various training hyperparameters, and will be passed to our `Trainer`.","metadata":{"id":"49dcba23"}},{"cell_type":"code","source":"model_name = model_checkpoint.split(\"/\")[-1]\nbatch_size = 8\n\nargs = TrainingArguments(\n    f\"{model_name}-finetuned-localization\",\n    evaluation_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    push_to_hub=True,\n)","metadata":{"id":"775cb3e7","execution":{"iopub.status.busy":"2023-11-28T04:52:04.833298Z","iopub.execute_input":"2023-11-28T04:52:04.834080Z","iopub.status.idle":"2023-11-28T04:52:04.843900Z","shell.execute_reply.started":"2023-11-28T04:52:04.834040Z","shell.execute_reply":"2023-11-28T04:52:04.842533Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2023-11-28T04:52:07.303871Z","iopub.execute_input":"2023-11-28T04:52:07.304764Z","iopub.status.idle":"2023-11-28T04:52:19.775173Z","shell.execute_reply.started":"2023-11-28T04:52:07.304718Z","shell.execute_reply":"2023-11-28T04:52:19.774196Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.1)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.24.3)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.17.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from evaluate import load\nimport numpy as np\n\nmetric = load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"id":"471cef9f","outputId":"baaf96ec-5004-4608-de37-5fd0c4e7ad02","execution":{"iopub.status.busy":"2023-11-28T04:52:19.777777Z","iopub.execute_input":"2023-11-28T04:52:19.778242Z","iopub.status.idle":"2023-11-28T04:52:23.165937Z","shell.execute_reply.started":"2023-11-28T04:52:19.778184Z","shell.execute_reply":"2023-11-28T04:52:23.164905Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd0ca647b25c496cbc170d5ebbac36ff"}},"metadata":{}}]},{"cell_type":"markdown","source":"And at last we're ready to initialize our `Trainer`:","metadata":{"id":"709dcf25"}},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"id":"e212b751","outputId":"73f6e47c-dca3-4a1d-bfbe-02ffc254b055","execution":{"iopub.status.busy":"2023-11-28T04:52:26.522463Z","iopub.execute_input":"2023-11-28T04:52:26.523475Z","iopub.status.idle":"2023-11-28T04:52:27.619651Z","shell.execute_reply.started":"2023-11-28T04:52:26.523420Z","shell.execute_reply":"2023-11-28T04:52:27.618729Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"Why do we pass along the `tokenizer` when we already preprocessed our data? This is because we will use it one last time to make all the samples we gather the same length by applying padding, which requires knowing the model's preferences regarding padding (to the left or right? with which token?). The `tokenizer` has a pad method that will do all of this right for us, and the `Trainer` will use it. You can customize this part by defining and passing your own `data_collator` which will receive samples like the dictionaries seen above and will need to return a dictionary of tensors.","metadata":{"id":"32924d0d"}},{"cell_type":"markdown","source":"We can now finetune our model by just calling the `train` method:","metadata":{"id":"72f7a24c"}},{"cell_type":"code","source":"trainer.train()","metadata":{"scrolled":true,"id":"9c3cf6da","outputId":"d0245d13-cee4-4fae-eb96-78e635be50da","execution":{"iopub.status.busy":"2023-11-28T04:52:30.373589Z","iopub.execute_input":"2023-11-28T04:52:30.374001Z","iopub.status.idle":"2023-11-28T05:05:21.386879Z","shell.execute_reply.started":"2023-11-28T04:52:30.373971Z","shell.execute_reply":"2023-11-28T05:05:21.385725Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231128_045254-env9ivj0</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ychauhanteam/huggingface/runs/env9ivj0' target=\"_blank\">crisp-serenity-8</a></strong> to <a href='https://wandb.ai/ychauhanteam/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ychauhanteam/huggingface' target=\"_blank\">https://wandb.ai/ychauhanteam/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ychauhanteam/huggingface/runs/env9ivj0' target=\"_blank\">https://wandb.ai/ychauhanteam/huggingface/runs/env9ivj0</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1170' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1170/1170 11:32, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.146773</td>\n      <td>0.955705</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.153800</td>\n      <td>0.135787</td>\n      <td>0.958113</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.073300</td>\n      <td>0.132532</td>\n      <td>0.961001</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1170, training_loss=0.10612111784454085, metrics={'train_runtime': 755.2856, 'train_samples_per_second': 24.75, 'train_steps_per_second': 1.549, 'total_flos': 1828684459715508.0, 'train_loss': 0.10612111784454085, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"Output :\n\n`TrainOutput(global_step=1170, training_loss=0.11126196201031024, metrics={'train_runtime': 745.437, 'train_samples_per_second': 25.077, 'train_steps_per_second': 1.57, 'total_flos': 1827808076607552.0, 'train_loss': 0.11126196201031024, 'epoch': 3.0})`","metadata":{}},{"cell_type":"markdown","source":"After three epochs we have a model accuracy of ~96%. With a larger starting model and more effort to ensure that the training data categories were cleanly separable, accuracy could almost certainly go a lot higher!","metadata":{"id":"dfec59f4"}}]}